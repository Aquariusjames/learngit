#  执行数据节点的磁盘热插拔
在不关闭DataNode的情况下替换HDFS磁盘。这被称为热插拔。
####  警告： 要求和限制
```
    CDH 5.4及更高版本支持热插拔。
    热插拔只能添加带有空数据目录的磁盘。
    删除磁盘不会将数据移出磁盘，这可能会导致数据丢失。
    不要同时在多台主机上执行热插拔。
```
## 使用Cloudera Manager执行数据节点的磁盘热插拔
**角色最低要求**：  Cluster Administrator 

1. 配置数据目录以删除要交换的磁盘：
    1. 选择导航栏上Cluster转到HDFS服务。
    1. 单击**Instances**选项卡。
    1. 单击受影响的DataNode。
    1. 单击**Configuration**选项卡。
    1. 选择左侧筛选器中的**Scope** > **DataNode**。
    1. 选择左侧筛选器中的**Category** > **Main**。
    1. 更改**DataNode Data Directory**属性的值，以删除要删除的磁盘的挂载点的目录。
        有哪些角色的都要删掉(hdfs,impala,yarn)

     **警告：仅对要计划热插拔磁盘的特定DataNode实例更改此属性的值。不要编辑此属性的**角色组**值。否则会导致数据丢失和角色变更。**

2. 单击**Save Changes**以提交更改。
3. 刷新受影响的DataNode。选择**Actions** > 刷新数据目录。
2. 删除旧磁盘并添加替换磁盘。
2. 更改DataNode Data Directory属性的值以添加作为您添加的磁盘的挂接点的目录。
2. 单击**Save Changes**以提交更改。
2. 刷新受影响的DataNode。选择 **Actions** > **Refresh Data Directories**。
2. 运行HDFS fsck 验证health of HDFS。

####  如果使用Cloudera Manager,就不要使用命令行来操作磁盘热插拔



换盘步骤

 df -h
 fdisk -l|more
 parted /dev/sdi
 ```
parted -s $DEVICE mklabel gpt mkpart primary ext3
 ```
mkfs.ext3 /dev/sdi1
```
ddp-dn-121:~ # mkfs.ext3 /dev/sdi
mke2fs 1.41.9 (22-Aug-2009)
/dev/sdi is entire device, not just one partition!
Proceed anyway? (y,n) y
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
183107584 inodes, 732421632 blocks
36621081 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=4294967296
22352 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks: 
  32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 
  4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968, 
  102400000, 214990848, 512000000, 550731776, 644972544

Writing inode tables: done                            
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: 
```


 mount /dev/sdi1 /mnt/sdi1/
 df -h
 

---
1. 先停角色 
2. 检查哪个磁盘损坏 导致数据写入/目录
3. mv /目录下的 文件到另一块挂载盘
4. 等新的磁盘换上后,将之前备份的mnm